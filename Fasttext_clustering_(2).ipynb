{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWxwu_YQ3ONZ",
        "outputId": "aa5aa1d7-9dd7-41e7-e300-bd9e2e60c778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.11.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.43.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n",
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYa-8lCb3sqe",
        "outputId": "a5f62d8b-5271-470c-8306-7b18b0916ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access 'your_script.sh': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!chmod +x your_script.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD2N2ZFh3_gK",
        "outputId": "4e55977b-51d0-4d96-f801-246d22f0971d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-01 16:27:25--  https://github.com/facebookresearch/fastText/archive/master.zip\n",
            "Resolving github.com (github.com)... 20.29.134.23\n",
            "Connecting to github.com (github.com)|20.29.134.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/facebookresearch/fastText/zip/refs/heads/master [following]\n",
            "--2023-12-01 16:27:26--  https://codeload.github.com/facebookresearch/fastText/zip/refs/heads/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [  <=>               ]   4.17M  15.9MB/s    in 0.3s    \n",
            "\n",
            "2023-12-01 16:27:26 (15.9 MB/s) - ‘master.zip’ saved [4370899]\n",
            "\n",
            "Archive:  master.zip\n",
            "a20c0d27cd0ee88a25ea0433b7f03038cd728459\n",
            "replace fastText-master/.circleci/cmake_test.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename: mv: cannot move 'fastText-master' to 'fastText/fastText-master': Directory not empty\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/facebookresearch/fastText/archive/master.zip\n",
        "!unzip master.zip\n",
        "!mv fastText-master fastText\n",
        "!rm master.zip\n",
        "!cd fastText && make\n",
        "!mv fastText/fasttext ./fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0mGyMbZ46q9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3edaa05-3887-44d3-baab-7808f48b4f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "terminate called after throwing an instance of 'std::invalid_argument'\n",
            "  what():  data/fasttext/your_model_name.bin cannot be opened for saving.\n"
          ]
        }
      ],
      "source": [
        "!./fasttext skipgram -input data/your_text_file.txt -output data/fasttext/your_model_name -dim 300 -minCount 79"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rou8gIHt7I6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c927e3fb-c7d2-4da3-f642-038a824b0135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 75.1M  100 75.1M    0     0  22.5M      0  0:00:03  0:00:03 --:--:-- 93.6M\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "\n",
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1V4rTx4yaAg0x1NY1MpNRY2Dp1nKeyOQ7\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1V4rTx4yaAg0x1NY1MpNRY2Dp1nKeyOQ7\" -o wiki_20190620_small.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# RandomForestClassifier 모델 인스턴스 생성\n",
        "model = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "qxD2LaClJYIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XEhe-oWap8q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "e36baf27-09a6-491a-f612-725c62f163bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-d83849f07513>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# TreeExplainer 인스턴스 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_perturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_perturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeEnsemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[1;32m    757\u001b[0m             ],\n\u001b[1;32m    758\u001b[0m         ):\n\u001b[0;32m--> 759\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"estimators_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Model has no `estimators_`! Have you called `model.fit`?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Model has no `estimators_`! Have you called `model.fit`?"
          ]
        }
      ],
      "source": [
        "#0.사용자 지정함수 설정,라이브러리 임포트\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import shap\n",
        "\n",
        "# TreeExplainer 인스턴스 생성\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "!pip install transformers\n",
        "!pip install kiwipiepy\n",
        "\n",
        "from kiwipiepy import Kiwi  ###\n",
        "from transformers import BertModel   ###\n",
        "\n",
        "def print_obj(obj, name):\n",
        "    print(\"%s:\\n%s\\n\" % (name, obj))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP0S5zNPZ7u7"
      },
      "outputs": [],
      "source": [
        "#1.데이터 불러오기(데이터형확인)(dim,shape)\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Google Drive에 있는 파일 읽기\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/top.csv' ###\n",
        "dataset = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blw2YUmAhYYB"
      },
      "outputs": [],
      "source": [
        "print(dataset.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.head())"
      ],
      "metadata": {
        "id": "0hEiG9H8RnP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "from gensim.models.word2vec import Text8Corpus\n",
        "from gensim.models import FastText\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/top.csv' ###\n",
        "dataset = pd.read_csv(file_path, header = None)\n",
        "\n",
        "print(dataset.dtypes)# 각 열의 데이터 타입 확인\n",
        "print(dataset.shape)# 데이터의 행과 열의 개수 확인"
      ],
      "metadata": {
        "id": "Lgm621pLYXhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [str(sentence).split() for sentence in dataset[1]]  # 1열의 데이터를 리스트로 변환\n",
        "sentences = [str(sentence).split() for column in dataset.columns for sentence in dataset[column]]\n",
        "\n",
        "print(sentences[:10])  # sentences 리스트의 첫 10개 요소를 출력"
      ],
      "metadata": {
        "id": "Ybb76gRVXmq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastText(vector_size=500, window=5, min_count=1)"
      ],
      "metadata": {
        "id": "8EvyNvpEXomX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab(sentences)  # 단어 사전 구축"
      ],
      "metadata": {
        "id": "GU7sU1kUXpsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(sentences, total_examples=model.corpus_count, epochs=10)  # 모델 훈련\n",
        "print(model)"
      ],
      "metadata": {
        "id": "w7iFghrOUAt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cENu60auNf6u"
      },
      "outputs": [],
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "# 모델을 저장하고 로드하는 코드\n",
        "model.save('fasttext_model')\n",
        "saved_model = FastText.load('fasttext_model')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "word_vectors = model.wv.vectors\n",
        "num_clusters = 10\n",
        "kmeans = KMeans(n_clusters=num_clusters)\n",
        "kmeans.fit(word_vectors)\n",
        "\n",
        "# 클러스터링 결과\n",
        "word_labels = model.wv.index_to_key\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "for word, label in zip(word_labels, cluster_labels):\n",
        "    print(f\"{word}: {label}\")"
      ],
      "metadata": {
        "id": "Hb3DfGdYiHDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습된 단어 벡터 가져오기\n",
        "word_vectors = model.wv.vectors\n",
        "\n",
        "# t-SNE를 사용하여 벡터 차원을 3으로 축소\n",
        "tsne = TSNE(n_components=3)\n",
        "vectors_3d = tsne.fit_transform(word_vectors)\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# 군집화 결과를 가져와서 각 데이터 포인트에 대한 색상 지정\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# 컬러맵 선택\n",
        "cmap = 'tab10'  # 예시로 'tab10' 컬러맵을 사용합니다\n",
        "\n",
        "# 3차원 벡터 시각화\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(vectors_3d[:, 0], vectors_3d[:, 1], vectors_3d[:, 2], c=cluster_labels, cmap=cmap)\n",
        "ax.set_title(\"Vector for 1 Keyword per announcement\")\n",
        "\n",
        "# 컬러바 추가\n",
        "cbar = plt.colorbar(scatter)\n",
        "\n",
        "# 그래프를 화면에 표시\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "# 그래프를 PNG 파일로 저장\n",
        "plt.savefig('cluster_result.png', dpi=300, format='png')\n",
        "\n",
        "\n",
        "# 축의 범위 설정\n",
        "ax.set_xlim([-300, 300])  # 적절한 xmin, xmax 값을 설정해주세요\n",
        "ax.set_ylim([-300, 300])  # 적절한 ymin, ymax 값을 설정해주세요\n",
        "ax.set_zlim([-300, 300])  # 적절한 zmin, zmax 값을 설정해주세요\n",
        "'''"
      ],
      "metadata": {
        "id": "LqWOcI1-8Iu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##2차원 그래프 시각화\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.title(\"Vector for 1 Keyword per announcement\")  # 제목 추가\n",
        "\n",
        "for i, label in enumerate(cluster_labels):\n",
        "    x, y = word_vectors_2d[i]\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word_labels[i], (x, y))\n",
        "\n",
        "# 이미지 파일로 저장\n",
        "plt.savefig('cluster_result.png', dpi=300, format='png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rZQMIKYS8Mae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# RandomForestClassifier 모델 인스턴스 생성\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# 모델을 훈련시키는 코드\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "50Mp4mWlI-n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# SHAP 값을 계산\n",
        "shap_values = explainer.shap_values(data)\n",
        "\n",
        "# SHAP 값을 출력\n",
        "print(shap_values)"
      ],
      "metadata": {
        "id": "z2XeHQA8JEmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt  ##plt로써 사용하겠다."
      ],
      "metadata": {
        "id": "6GXOS6sfKzhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import numpy as np\n",
        "import fasttext\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "word_vectors = model.wv.vectors\n",
        "num_clusters = 7\n",
        "kmeans = KMeans(n_clusters=num_clusters)\n",
        "kmeans.fit(word_vectors)\n",
        "\n",
        "# 클러스터링 결과\n",
        "word_labels = model.wv.index_to_key\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "for word, label in zip(word_labels, cluster_labels):\n",
        "    print(f\"{word}: {label}\")\n",
        "\n",
        "#데이터의 특징벡터를 각각 분할하여 사용\n",
        "x1 = feature[:,0]\n",
        "x2 = feature[:,1]\n",
        "\n",
        "#데이터의 전체 갯수와 특징벡터의 수를 확인해보자.\n",
        "number_data     = np.size(feature, 0)\n",
        "number_feature  = np.size(feature, 1)\n",
        "\n",
        "print('number of data : {}'.format(number_data))\n",
        "print('number of feature : {}'.format(number_feature))\n",
        "'''"
      ],
      "metadata": {
        "id": "cllpDBQ3K2MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (1-2) (데이터 측면)데이터 시각화\n",
        "\n",
        "# 군집화를 시행하기 전 데이터가 어떻게 구성되어 있는지 확인해보자\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title('input data')\n",
        "plt.xlabel(\"x_1\")\n",
        "plt.ylabel(\"x_2\")\n",
        "plt.plot(x1,x2,'o', c=\"blue\")"
      ],
      "metadata": {
        "id": "0QSg3KnnK4KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치를 평균으로 대체\n",
        "feature = np.where(np.isnan(feature), np.nanmean(feature), feature)\n",
        "\n",
        "\n",
        "# K-평균 군집화(K-means Clustering)\n",
        "\n",
        "# 라이브러리 불러오기 (Importing the libraries)\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "\n",
        "# (3) (모델 측면) sklearn 라이브러리를 이용하여 K-평균 클러스터링 불러오기 (k=5)\n",
        "# n_clusters 를 통해서 해당 데이터를 몇개의 군집으로 분류할 것인지를 결정해준다.\n",
        "model = KMeans(n_clusters=5)\n",
        "#model.fit(feature)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# numpy array를 pandas DataFrame으로 변환\n",
        "df = pd.DataFrame(feature)\n",
        "\n",
        "# 각 열에 대해 결측치가 있는지 확인\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 각 열의 평균으로 NaN 값을 대체\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# DataFrame을 다시 numpy array로 변환\n",
        "feature = df.values\n",
        "\n",
        "# KMeans 모델 학습\n",
        "model.fit(feature)\n",
        "\n",
        "# 예측\n",
        "predict = pd.DataFrame(model.predict(feature))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# (4) (학습 과정) sklearn 라이브러리를 이용하여 알고리즘 수행하기.\n",
        "predict = pd.DataFrame(model.predict(feature))\n",
        "\n",
        "# (5) (성능 평가) K= 5일때, 결과 시각화\n",
        "def plot_cluster(feature, label_feature):     ##시각화해야함\n",
        "    x1 = feature[:,0] ## :은 모든 값 가져오기\n",
        "    x2 = feature[:,1]\n",
        "    plt.figure(figsize=(8,8))  ##창사이즈 먼저 설정해야 함.\n",
        "    plt.title('cluster')   ##이미지 타이틀\n",
        "    plt.xlabel(\"x_1\")   ##x축에 대한 레이블\n",
        "    plt.ylabel(\"x_2\")  ##y축에 대한 레이블\n",
        "    #각각 데이터 별 분류된 군집에 따라서 색상을 다르게 표시해준다\n",
        "    #데이터를 표기할 때 \"o\"를 사용하면 점 형태로 표현할 수 있다.\n",
        "    #c는 color을 의미하며 색상을 작성하면 해당 색상으로 데이터를 표기한다.\n",
        "    plt.plot(x1[label_feature==0], x2[label_feature==0],'o', c=\"skyblue\")  ##==은 서로 같냐?, true일때 1, false이면 0, 이걸 인덱싱으로 사용가능\n",
        "    plt.plot(x1[label_feature==1], x2[label_feature==1],'o', c=\"yellow\")   ##인덱싱 원하는 값 셀렉트 하기 위해서\n",
        "    plt.plot(x1[label_feature==2], x2[label_feature==2],'o', c=\"green\")\n",
        "    plt.plot(x1[label_feature==3], x2[label_feature==3],'o', c=\"red\")\n",
        "    plt.plot(x1[label_feature==4], x2[label_feature==4],'o', c=\"violet\")  ##c라는 옵션은 색상 다르게 적용 가능\n",
        "    plt.tight_layout()\n",
        "    plt.show()   ##!!!중요!!!!show는 보여주는 것\n",
        "    plt.save.fig('./image.png')  ##!!!!!!저장하기(캡처하지 말고 저장해서 이미지로 쓰기!)\n",
        "    #!!!!!!!플젝_비교분석)ppt에 전/후 a방법, b방법 어떻게 바뀌었는지 augmentation 전후, 한눈에 알 수 있도록!!!!!!!!!!\n",
        " ##plot이 5번이나 돌아감, 값이 살아 있으면 누적되는 거. 새로 초기화하지 않으면 같이 그림이 그려질 수도. 새로 할당하고 싶으면 새로 그려야 함.\n",
        "\n",
        "\n",
        "    print(predict)\n",
        "    print('--------------')\n",
        "    print(predict.values)\n",
        "    print('-------------')\n",
        "    print(print.values.ravel()) ##1차원으로 나옴 레벨 함수 때문에. 단계별로 해석할 줄 알아야\n",
        "    print('-------------')\n",
        "plot_cluster(feature, predict.values.ravel())"
      ],
      "metadata": {
        "id": "M9fn1GYoK-UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-EysT-kvLD77"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}