{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4jThyX/mpiuVJd6PS0JRL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Y00nnye/Teamproject_23-2/blob/douen/_2_bert%2Bvoting%2Bevaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc4dgk8ytmXy"
      },
      "outputs": [],
      "source": [
        "#1.bert사용\n",
        "#bert_keyword초기화\n",
        "bert_keyword=[]\n",
        "\n",
        "# X_kiwi_combined의 길이만큼 반복: 모든 단어의 중요도 출력\n",
        "for i in range(len(X_kiwi_combined)):\n",
        "    # 키워드 추출\n",
        "    keywords = kw_model.extract_keywords(X_kiwi_combined[i], keyphrase_ngram_range=(1, 1), stop_words=None, top_n=1)\n",
        "\n",
        "    # bert_keyword 에 키워드 추가\n",
        "    bert_keyword.append(keywords)\n",
        "\n",
        "for i, value in enumerate(bert_keyword):\n",
        "    print(f\"value at index {i}: {value}\")\n",
        "\n",
        "#위의 bert_keyword df화\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 주어진 데이터:bert_keyword\n",
        "\n",
        "# DataFrame으로 변환\n",
        "df = pd.DataFrame([(item[0], item[1]) for sublist in bert_keyword for item in sublist], columns=['단어', '중요도'])\n",
        "\n",
        "# 결과 출력\n",
        "display(df)\n",
        "\n",
        "def pad_sequence(sequence, max_length, padding_value=0):\n",
        "    padded_sequence = sequence[:max_length] + [padding_value] * max(0, max_length - len(sequence))\n",
        "    return padded_sequence\n",
        "\n",
        "# 최대 길이\n",
        "max_length = 20\n",
        "\n",
        "# 패딩된 결과\n",
        "padded_X_kiwi = [pad_sequence(row, max_length) for row in X_kiwi]\n",
        "\n",
        "# 결과 출력\n",
        "for row in padded_X_kiwi:\n",
        "    print(row)\n",
        "\n",
        "df_X = pd.DataFrame(padded_X_kiwi)\n",
        "\n",
        "# 결과 출력\n",
        "print(df_X)\n",
        "\n",
        "df_keyword = pd.DataFrame(bert_keyword)\n",
        "\n",
        "# 튜플 분해 및 새로운 열 생성\n",
        "df_keyword[['단어', '중요도']] = pd.DataFrame(df_keyword[0].tolist(), index=df_keyword.index)\n",
        "\n",
        "# 기존 열 삭제\n",
        "df_keyword = df_keyword.drop(columns=[0])\n",
        "\n",
        "# 결과 출력\n",
        "print(df_keyword)\n",
        "\n",
        "# df와 bert_keyword를 수평으로 연결\n",
        "result_df = pd.concat([df_X,df_keyword], axis=1)\n",
        "\n",
        "# 결과 출력\n",
        "display(result_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.hardvoting(임의의 thresholds설정 후 직접 구현)\n",
        "\n",
        "#hardvoting직접구현(중요도 값=> 0.6 0.7 0.8처럼 임의로 기준치 설정후=>hardvoting직접구현)\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# 중요도 기준 설정\n",
        "thresholds = [0.5, 0.6, 0.7]\n",
        "\n",
        "# 투표 수집\n",
        "votes = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    # 중요도 기준에 따라 투표\n",
        "    votes.append([1 if importance >= threshold else 0 for importance in df_keyword['중요도']])\n",
        "\n",
        "# vote를 label로 변환\n",
        "labels = [1 if sum(vote) > len(vote) / 2 else 0 for vote in zip(*votes)]\n",
        "\n",
        "# 중간 결과 출력\n",
        "print(\"중간 투표 결과:\")\n",
        "for threshold, vote in zip(thresholds, votes):\n",
        "    print(f\"중요도 기준 {threshold}에 대한 투표 결과: {vote}\")\n",
        "\n",
        "print(\"labels\")\n",
        "print(labels)\n",
        "\n",
        "# 최종 키워드 여부 결정\n",
        "df_keyword['키워드 여부'] = labels\n",
        "\n",
        "# 최종 결과 DataFrame 생성\n",
        "result_df = df_keyword[['단어', '중요도', '키워드 여부']]\n",
        "\n",
        "# 최종 결과 출력\n",
        "print(\"\\n최종 결과:\")\n",
        "display(result_df)"
      ],
      "metadata": {
        "id": "x50I_k3St_Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.hard,soft voting(3different classifier)\n",
        "\n",
        "#classifier:logistic, knn, decision tree\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#(1)로지스틱 회귀 계산\n",
        "#soft Voting Classifier(로지스틱 회귀)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_keyword['중요도'].values.reshape(-1, 1),\n",
        "                                                    labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression 모델 학습\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Logistic Regression 모델의 테스트 데이터에 대한 예측 확률\n",
        "logistic_predictions_proba = logistic_model.predict_proba(X_test)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Logistic Regression 모델의 예측 확률:\")\n",
        "print(logistic_predictions_proba)\n",
        "print(logistic_predictions_proba.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#(2)softvotingfrom sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 분리\n",
        "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(\n",
        "    df_keyword['중요도'].values.reshape(-1, 1),\n",
        "    labels,\n",
        "    df_keyword.index,  # 인덱스를 따로 저장\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Voting Classifier에 사용할 분류기들 정의\n",
        "classifier1 = KNeighborsClassifier(n_neighbors=3)\n",
        "classifier2 = DecisionTreeClassifier(random_state=42)\n",
        "classifier3 = LogisticRegression()\n",
        "\n",
        "# Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('knn', classifier1),       # KNeighborsClassifier\n",
        "        ('tree', classifier2),      # DecisionTreeClassifier\n",
        "        ('logistic', classifier3)   # LogisticRegression\n",
        "    ],\n",
        "    voting='soft',  # Soft Voting 설정\n",
        "    weights=[1, 1, 1]  # 각 분류기에 가중치 부여\n",
        ")\n",
        "\n",
        "# Voting Classifier 모델 학습\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# KNeighborsClassifier 모델 학습\n",
        "classifier1.fit(X_train, y_train)\n",
        "\n",
        "# 각 분류기의 예측 확률을 가져옵니다.\n",
        "knn_predictions_proba = classifier1.predict_proba(X_test)\n",
        "\n",
        "# Voting Classifier 모델 학습\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 각 분류기에 대해 fit 메소드 호출\n",
        "classifier1.fit(X_train, y_train)\n",
        "classifier2.fit(X_train, y_train)\n",
        "classifier3.fit(X_train, y_train)\n",
        "\n",
        "# 각 분류기의 예측 확률을 가져옵니다.\n",
        "knn_predictions_proba = classifier1.predict_proba(X_test)\n",
        "tree_predictions_proba = classifier2.predict_proba(X_test)\n",
        "logistic_predictions_proba = classifier3.predict_proba(X_test)\n",
        "\n",
        "# 각 분류기의 예측 확률을 가져옵니다.\n",
        "knn_predictions_proba = classifier1.predict_proba(X_test)\n",
        "tree_predictions_proba = classifier2.predict_proba(X_test)\n",
        "logistic_predictions_proba = classifier3.predict_proba(X_test)\n",
        "\n",
        "# Soft Voting의 결과를 가져옵니다.\n",
        "soft_voting_predictions_proba = voting_classifier.predict_proba(X_test)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 각 분류기의 예측 확률을 데이터프레임으로 변환\n",
        "knn_proba_df = pd.DataFrame(knn_predictions_proba, columns=['KNeighborsClassifier_0', 'KNeighborsClassifier_1'])\n",
        "tree_proba_df = pd.DataFrame(tree_predictions_proba, columns=['DecisionTreeClassifier_0', 'DecisionTreeClassifier_1'])\n",
        "logistic_proba_df = pd.DataFrame(logistic_predictions_proba, columns=['LogisticRegression_0', 'LogisticRegression_1'])\n",
        "voting_proba_df = pd.DataFrame(voting_predictions_proba, columns=['SoftVotingClassifier_0', 'SoftVotingClassifier_1'])\n",
        "\n",
        "# 예측 확률 데이터프레임을 수평으로 결합\n",
        "combined_proba_df = pd.concat([knn_proba_df, tree_proba_df, logistic_proba_df, voting_proba_df], axis=1)\n",
        "\n",
        "# 결과 출력\n",
        "display(combined_proba_df)\n",
        "\n",
        "#anntation(plotly)\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_probabilities_plotly(probabilities, classifier_name):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=list(range(len(probabilities))),\n",
        "                             y=probabilities[:, 1],\n",
        "                             mode='lines+markers',\n",
        "                             name=f'{classifier_name} - Class 1 Probability'))\n",
        "\n",
        "    fig.update_layout(title=f'{classifier_name} Predicted Probabilities',\n",
        "                      xaxis_title='test Index',\n",
        "                      yaxis_title='Probability')\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "# 각 분류기의 예측 확률을 plotly로 시각화\n",
        "plot_probabilities_plotly(knn_predictions_proba, 'KNeighborsClassifier')\n",
        "plot_probabilities_plotly(tree_predictions_proba, 'DecisionTreeClassifier')\n",
        "plot_probabilities_plotly(logistic_predictions_proba, 'LogisticRegression')\n",
        "plot_probabilities_plotly(voting_predictions_proba, 'SoftVotingClassifier')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#(3)hard voting(classifier:logistic+knn+desicion tree)\n",
        "\n",
        "# Voting Classifier에 사용할 분류기들 정의\n",
        "classifier1 = KNeighborsClassifier(n_neighbors=3)\n",
        "classifier2 = DecisionTreeClassifier(random_state=42)\n",
        "classifier3 = LogisticRegression()\n",
        "\n",
        "# Hard Voting Classifier\n",
        "hard_voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('knn', classifier1),       # KNeighborsClassifier\n",
        "        ('tree', classifier2),      # DecisionTreeClassifier\n",
        "        ('logistic', classifier3)   # LogisticRegression\n",
        "    ],\n",
        "    voting='hard'  # Hard Voting 설정\n",
        ")\n",
        "\n",
        "# Voting Classifier 모델 학습\n",
        "hard_voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 각 분류기에 대해 fit 메소드 호출\n",
        "classifier1.fit(X_train, y_train)\n",
        "classifier2.fit(X_train, y_train)\n",
        "classifier3.fit(X_train, y_train)\n",
        "\n",
        "# 각 분류기의 예측을 가져옵니다.\n",
        "knn_predictions = classifier1.predict(X_test)\n",
        "tree_predictions = classifier2.predict(X_test)\n",
        "logistic_predictions = classifier3.predict(X_test)\n",
        "\n",
        "# Hard Voting의 결과를 가져옵니다.\n",
        "hard_voting_predictions = hard_voting_classifier.predict(X_test)\n",
        "\n",
        "# 결과 출력\n",
        "result_df_hard_voting = pd.DataFrame({\n",
        "    '중요도': df_keyword.loc[indices_test, '중요도'],\n",
        "    'KNeighborsClassifier': knn_predictions,\n",
        "    'DecisionTreeClassifier': tree_predictions,\n",
        "    'LogisticRegression': logistic_predictions,\n",
        "    'HardVoting': hard_voting_predictions\n",
        "})\n",
        "\n",
        "display(result_df_hard_voting)\n",
        "\n",
        "#annotation(plotpy)\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_predictions_plotly(predictions, classifier_name):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=list(range(len(predictions))),\n",
        "                             y=predictions,\n",
        "                             mode='lines+markers',\n",
        "                             name=f'{classifier_name} Predictions'))\n",
        "\n",
        "    fig.update_layout(title=f'{classifier_name} Predictions',\n",
        "                      xaxis_title='test Index',\n",
        "                      yaxis_title='Predictions')\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "# 각 분류기의 예측을 plotly로 시각화\n",
        "plot_predictions_plotly(knn_predictions, 'KNeighborsClassifier')\n",
        "plot_predictions_plotly(tree_predictions, 'DecisionTreeClassifier')\n",
        "plot_predictions_plotly(logistic_predictions, 'LogisticRegression')\n",
        "plot_predictions_plotly(hard_voting_predictions, 'HardVotingClassifier')\n",
        "\n"
      ],
      "metadata": {
        "id": "ZNH92OURuJ2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.성능 비교\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Soft Voting의 성능 평가\n",
        "soft_voting_accuracy = accuracy_score(y_test, soft_voting_predictions)\n",
        "soft_voting_precision = precision_score(y_test, soft_voting_predictions)\n",
        "soft_voting_recall = recall_score(y_test, soft_voting_predictions)\n",
        "soft_voting_f1 = f1_score(y_test, soft_voting_predictions)\n",
        "\n",
        "# Hard Voting의 성능 평가\n",
        "hard_voting_accuracy = accuracy_score(y_test, hard_voting_predictions)\n",
        "hard_voting_precision = precision_score(y_test, hard_voting_predictions)\n",
        "hard_voting_recall = recall_score(y_test, hard_voting_predictions)\n",
        "hard_voting_f1 = f1_score(y_test, hard_voting_predictions)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Soft Voting 성능:\")\n",
        "print(f\"정확도: {soft_voting_accuracy:.4f}\")\n",
        "print(f\"정밀도: {soft_voting_precision:.4f}\")\n",
        "print(f\"재현율: {soft_voting_recall:.4f}\")\n",
        "print(f\"F1 점수: {soft_voting_f1:.4f}\")\n",
        "\n",
        "print(\"\\nHard Voting 성능:\")\n",
        "print(f\"정확도: {hard_voting_accuracy:.4f}\")\n",
        "print(f\"정밀도: {hard_voting_precision:.4f}\")\n",
        "print(f\"재현율: {hard_voting_recall:.4f}\")\n",
        "print(f\"F1 점수: {hard_voting_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "T7BmmrQhvNYb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}